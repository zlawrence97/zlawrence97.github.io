<html>
<title>Comuter Vision</title>

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<head>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Cabin|Arvo|Source+Serif+Pro">
  <link rel="stylesheet" href="styles.css">
  <style>
    body{
      font-family:Cabin;
    }
    
    .column {
      float: left;
      width: 23.33%;
      padding: 5px;
    }

    .row::after {
      content: "";
      clear: both;
      display: flex;
    }
    
  </style> 
</head>

<body>
  <header class="header" style="padding: 1em; clear: left; text-align:center; background-color:black; color:white;">
    <h1 class="title">Final Project - Image Tracking using Tensorflow</h1>
    <h2 class="divide">_____________________________________________________________</h2>
    <h3 class="naem">Paul Azzy, John Shepherd and Zuri Lawrence</h3>
  </header>
  <div class="project">
    <article class="full-explanation">
      <div class="content">
        <article class="write-up">
          <div class="inner">
            <aside class="explanation" style="margin-right: 770px; border-left: 200px; padding: 1em;">
              <div class="intro">
		        <h2 class="desc">Introduction</h2>
		        <p>Given that the current state of computer vision as it applies to sports is an ongoing research topic, 
		        we became interested in this project and decided to pursue it (Thomas, G., et al., Computer Vision for 
		        Sports: Current Applications and Research Topics, 2017).  Sports analytics is a huge area driven by data. 
		        Archetyping a system to output the desired data for a given sports scenario would be invaluable to every 
		        institution that utilizes sports statistics.<br>
		        So, the objective of this project was to train an object detection model to track players, balls, and 
		        referees in sport videos. We decided to start with these classes as they are the fundamental elements to a 
		        sports game.  We wanted to train across multiple sports to attempt to create a system that could be universally 
		        applied to any sport that one wishes to collect data on; so, as a basis, we trained our model to recognize 
		        basketball, baseball, soccer, and tennis videos. Depending on which video is used, the model is able to tell 
		        which sport the athletes in the scene are playing, as well as the kind of sport ball that is being used.<br> 
				While being able to track people and objects in a scene may seem trivial at first, the implications of having 
				such tracking have endless applications. For example, in this sports recognition scenario, we could hypothetically 
				train an object detection model to recognize players on opposing teams and create predictive models over the 
				course of multiple games played against each other to determine the plays each team is likely to use. Further, 
				we could potentially output more concrete statistics such as how close a baseball player was to hitting the ball 
				or outputting why someone’s shot may be off in basketball.<br>
				Tensorflow is currently an extremely popular library in the machine learning field so we decided to go this route.
				Tensorflow uses deep learning to train on large amounts of data.  This library was perfect for our purposes.  
				In his <a href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" target="_blank">
				tutorial</a>, Dat Tran creates a raccoon classifier with Tensorflow.  We took this tutorial as a motivation to 
				make our own player/ball classifier.<br>
		        </p>
	          </div>
	          <div class="related-work">
	            <h2 class="title">Related Work</h2>
	            <p>Computer Vision within sports is a hot topic and many publications have been released in just the past year 
	            concerning player and ball tracking.  Earlier takes on the topic around 2000 focus on specific camera calibration 
	            and lens distortion correction to detect players and balls (J. Pers, Computer Vision System for Tracking Players 
	            in Sports Games, 2000).  This hardware solution is not too realistic in the end as a whole system must be 
	            calibrated for each specific instance that one wishes to observe.  Recent research results to software solutions 
	            specifically using machine learning to detect players and balls.  Graham Thomas et al. discuss current vision-based
	            systems, the impact on various sports, and open issues of fully automated player/ball tracking (Computer Vision 
	            for Sports: Current Applications and Research Topics, 2017).  According to his team, fully automated sports/ball 
	            tracking is an ongoing problem that is still being solved.  This problem motivated are team to archetype a potential
	            solution using the latest methods of deep learning and neural networks.<br>
	            </p>
	          </div>
	          <div class="approach">
	            <h2 class="title">Our Approach</h2>
	              <h3>Data Handling</h3>
	              <p>As previously mentioned, TensorFlow was used for our machine learning purposes. While the installation of the 
	              library was fairly simple, the steps required to train the object detection model were fairly convoluted. The 
	              first step we made towards making our model was scraping, downloading, and labeling images from Google Images 
	              and sports highlight videos. Together, we gathered and labeled nearly 500 images from all four sports we wanted 
	              to detect players, balls, and referees from. The labels for all the images were saved in .xml files that were 
	              then converted to a single .csv file. This .csv file was then split up into testing and training .csv files. 10% 
	              of the dataset was used for training, and 10% of the dataset was used for testing. The reason for this split is 
	              so that we don’t test on the same data that we trained on. That would be counterproductive to ensuring that the 
	              model we created is actually applicable in a real world setting. These .csv files were then converted into 
	              .record files which is the data set format that Tensorflow accepts for image analysis.<br>
	              </p>
	              <div class="data-gathered">
	      			<img class="hybrid img responsive pull-left" src="../images/cv4/data-training1.png" alt="data1" style="width: 906px; height: 618px; margin-bottom: .5em"> 
	      			<img class="hybrid img responsive pull-left" src="../images/cv4/data-training2.png" alt="data2" style="width: 862px; height: 610px; margin-bottom: .5em">
          			<img class="hybrid img responsive pull-left" src="../images/cv4/data-training3.png" alt="data3" style="width: 896px; height: 728px; margin-bottom: .5em">
        		    <img class="hybrid img responsive pull-left" src="../images/cv4/data-training4.png" alt="data4" style="width: 913px; height: 734px; margin-bottom: .5em">
				  </div>
				  <div class="model-training">
				    <h3>Model Training</h3>
				    <p>The Object Detection API had to be downloaded separately from TensorFlow.  This API holds all the functions 
				    and capabilities we needed to utilize to train our model.  We did utilize a previously trained model that was 
				    trained for other objects as it holds parameters that can take a few days to obtain if we started a training job
				    from scratch. It’s much faster to build off a network that has already been trained than to start from scratch.
				    This method is often known as transfer learning. TensorFlow is one of the first libraries to make transfer learn
				    ing somewhat easy to implement. We also created a label file that explicitly states each of the classes that we
				    desire to train on (basketball, soccer player, referee, etc.)<br>
				    During a training job, TensorFlow creates multiple checkpoints. The job can be stopped at any time and can be 
				    picked up from the last checkpoint saved. Before deploying the Object Detection API, Google trained multiple 
				    models on different datasets and released their latest checkpoint files to the public. We’re using the resnet 
				    model as it seemed to be the standard one that was generalized to any scenario a user wanted to configure the 
				    model to.  This model was placed in its own folder in the Object Detection API’s main directory. The corresponding 
				    config file in the training directory was modified to read training and test data from the data folder, read 
				    the previously trained checkpoint file from the downloaded model’s folder, and read the label .pbtxt file from 
				    the training directory.<br> 
				    TensorFlow uses configuration files to specify initializations of messages within protobuf files. These protobuf 
				    files basically act as data structures that can be read from most languages using Google’s Protobuf API. 
				    Tensorflow libraries use protobuf files because its library is compatible with both Python and C++. Therefore, 
				    this enables developers to be able to easily transfer models and configurations when using one language or the 
				    other. The configurations specified in the .config file end up dictating the design of the neural net through 
				    the abstracted protobuf files. Moreover, once the API was set up as needed, the train.py script from the API 
				    was run. While running we could view the status of the training job using TensorBoard, a program that visualizes
				     the progression of a model’s training. The most important piece that we kept an eye out for was the loss 
				     function. We wanted to run the job until we saw the loss function plateauing around 1 or preferably less than 1.
				     <br>
				    </p>
				  </div>          
	          </div>
	          <div class="implementation">
	            <h2 class="title">Implementation and Analysis</h2>
	            <p>Once the model reached our desired loss of approximately .3 after about 6 hours of training, we stopped the 
	            training and froze the most recent model checkpoint and saved it as a .pb file (or our model file). This .pb file 
	            is then used in our video object detection program alongside the label .pbtxt file. Our video object detection 
	            program then takes every frame of an input video and runs it through a visualizer function provided by the Object 
	            Detection API. This visualization function uses the label map as well as the exported model and then returns the 
	            same image with boxes enclosing the objects that were found in that frame along with its confidence in the classification. 
	            These modified frames are then added to a new output video. This process of extracting, analyzing, and appending 
	            each frame takes approximately 5-8 seconds.<br>
	            The overall classification accuracy of the model for a real-world application was good for basketball, soccer, and 
	            tennis. However, some sports posed a difficulty.  The classification of baseball players and baseballs was hit or 
	            miss (pun intended) most of the time. This is mainly due to the to the fact that our trained data set was relatively
	            small compared to what a neural network needs to train for extreme accuracy across all mediums. For example, when 
	            zooming out into the field, baseball players were often classified as soccer players probably because we had more 
	            data on soccer players in a zoomed out view than we did for baseball players. The simple solution to this would be 
	            to get more data on baseball players to train on, but as this is a three person project and we had 2-3 weeks, we 
	            suffice it to say that if this project is to take a step forward, more training data will be needed.<br>
	            </p>
	            <h3>Results</h3>
	            <div class="result-images">
	              <p>Before</p>
	              <img class="hybrid img responsive pull-left" src="../images/cv4/jordan-before.jpg" alt="data1" style="width: 480px; height: 275px; margin-bottom: .5em">
	              <p>After</p>
	              <img class="hybrid img responsive pull-left" src="../images/cv4/jordan.jpg" alt="data1" style="width: 480px; height: 275px; margin-bottom: .5em"><br><br>
	              <img class="hybrid img responsive pull-left" src="../images/cv4/soccer-wide.png" alt="data1" style="width: 360px; height: 275px; margin-bottom: .5em">
	              <img class="hybrid img responsive pull-left" src="../images/cv4/pitcher.png" alt="data1" style="width: 360px; height: 275px; margin-bottom: .5em">
	              <h4>Tracking Results</h4>
	              <img class="hybrid img responsive pull-left" src="../images/cv4/Baseball Gif.gif" alt="data1" style="width: 640px; height: 320px; margin-bottom: .5em">
	              <img class="hybrid img responsive pull-left" src="../images/cv4/Basketball Gif.gif" alt="data1" style="width: 640px; height: 320px; margin-bottom: .5em">
	              <img class="hybrid img responsive pull-left" src="../images/cv4/Soccer Gif.gif" alt="data1" style="width: 640px; height: 320px; margin-bottom: .5em">
	              <img class="hybrid img responsive pull-left" src="../images/cv4/Tennis Gif.gif" alt="data1" style="width: 640px; height: 320px; margin-bottom: .5em">
	            </div>
	          </div>
	          <div class="wrap-up">
	            <h3 class="title">Conclusions</h3>
	            <p>Overall, this project was a great introduction to the field of image recognition using machine learning. It gave
	            us a reason to explore trends in training deep and neural networks right now and to jump through the hurdles of 
	            getting started using technologies that back these trends. TensorFlow has been a term that we’ve often heard around,
	            and it was nice to finally get hands-on experience using it.<br>
	            For the difficulty of the project, getting the environment setup and understanding methodology of how to use 
	            TensorFlow was definitely the hardest part. Due to its bountiful functionality, step by step procedures have to be 
	            followed exactly in order to get the program to do what you want. However, this was also the most rewarding part of
	            the project because we can all confidently say that we are able to use TensorFlow now. Given that it’s a hot 
	            library in the machine learning field, that’s a good skill to have now. Moreover, the most tedious part of this 
	            project was definitely the scraping and labeling of images. It took roughly  2 hours for each group member to find 
	            images and label them for a single sport. In total, each member spent around 8 hours each just finding and labeling
	            images.<br>
	            One major roadblock that our group ran into was that no one on the team had a computer powerful enough to 
	            effectively run deep learning algorithms and train a model in a timely manner. For example, running a job on one of
	            our laptops took roughly 7 hours to to train a model with a loss of 20 down to a loss of 4. We then turned to 
	            Google Cloud Services to run our jobs. Setting up the TensorFlow environment on Google Cloud also presented its own
	            difficulties. Once set up, we were able to train our models using cloud computing. However, the cost of the service 
	            was too high to make retraining our neural net more than twice viable. Given better resources available to us, we 
	            could have tested more configurations of our network in order to obtain better results.
	            </p>
	          </div>
	        </aside>
          </div>
	    </article>
      </div>
    </article>

  <style>
    body{
      vertical-align:middle;
      background-color:fefefe;
      color:black;
      text-align:pull-left;
    }
  </style>

</body>
  
  
</html>
